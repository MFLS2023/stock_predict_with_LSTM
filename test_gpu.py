import torch
import sys

print("=" * 60)
print("PyTorch GPU é…ç½®æµ‹è¯•")
print("=" * 60)
print()

# åŸºæœ¬ä¿¡æ¯
print("ğŸ Pythonä¿¡æ¯:")
print(f"  ç‰ˆæœ¬: {sys.version}")
print(f"  å¯æ‰§è¡Œæ–‡ä»¶: {sys.executable}")
print()

# PyTorchä¿¡æ¯
print("ğŸ”¥ PyTorchä¿¡æ¯:")
print(f"  ç‰ˆæœ¬: {torch.__version__}")
print(f"  å®‰è£…è·¯å¾„: {torch.__file__}")
print()

# CUDAä¿¡æ¯
print("ğŸ® CUDAä¿¡æ¯:")
print(f"  CUDAå¯ç”¨: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    print(f"  CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"  cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version()}")
    print(f"  GPUæ•°é‡: {torch.cuda.device_count()}")
    print()
    
    # æ¯ä¸ªGPUçš„è¯¦ç»†ä¿¡æ¯
    print("ğŸ–¥ï¸  GPUè®¾å¤‡ä¿¡æ¯:")
    for i in range(torch.cuda.device_count()):
        print(f"  GPU {i}:")
        print(f"    åç§°: {torch.cuda.get_device_name(i)}")
        print(f"    æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB")
        print(f"    è®¡ç®—èƒ½åŠ›: {torch.cuda.get_device_properties(i).major}.{torch.cuda.get_device_properties(i).minor}")
    print()
    
    # æµ‹è¯•GPUè®¡ç®—
    print("ğŸ§ª GPUè®¡ç®—æµ‹è¯•:")
    try:
        # åˆ›å»ºæµ‹è¯•å¼ é‡
        x = torch.rand(1000, 1000).cuda()
        y = torch.rand(1000, 1000).cuda()
        
        # çŸ©é˜µä¹˜æ³•
        import time
        start = time.time()
        z = torch.mm(x, y)
        torch.cuda.synchronize()  # ç­‰å¾…GPUå®Œæˆ
        end = time.time()
        
        print(f"  âœ… çŸ©é˜µä¹˜æ³•æµ‹è¯•æˆåŠŸï¼")
        print(f"  è®¡ç®—æ—¶é—´: {(end - start) * 1000:.2f} ms")
        print(f"  ç»“æœå½¢çŠ¶: {z.shape}")
        print(f"  å½“å‰GPUå†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated() / 1024**2:.2f} MB")
        print(f"  å³°å€¼GPUå†…å­˜ä½¿ç”¨: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB")
        print()
        
        # æ¸…ç†
        del x, y, z
        torch.cuda.empty_cache()
        
        print("=" * 60)
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼GPUé…ç½®æ­£å¸¸ï¼")
        print("=" * 60)
        print()
        print("ğŸ’¡ æç¤º:")
        print("  - æ‚¨å¯ä»¥åœ¨è®­ç»ƒè®¾ç½®ä¸­é€‰æ‹©å…·ä½“çš„GPU")
        print("  - å¯¹äºå°æ¨¡å‹ï¼ŒGPUå’ŒCPUæ€§èƒ½å·®å¼‚ä¸å¤§")
        print("  - å¯¹äºå¤§æ•°æ®é›†å’Œå¤æ‚æ¨¡å‹ï¼ŒGPUä¼šæ˜¾è‘—åŠ é€Ÿè®­ç»ƒ")
        
    except Exception as e:
        print(f"  âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
        print()
        print("å»ºè®®:")
        print("  1. æ£€æŸ¥CUDAé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("  2. å°è¯•é‡å¯è®¡ç®—æœº")
        print("  3. æ›´æ–°æ˜¾å¡é©±åŠ¨")

else:
    print("  âŒ CUDAä¸å¯ç”¨")
    print()
    print("å¯èƒ½çš„åŸå› :")
    print("  1. æœªå®‰è£…GPUç‰ˆæœ¬çš„PyTorch")
    print("  2. æ˜¾å¡é©±åŠ¨æœªæ­£ç¡®å®‰è£…")
    print("  3. CUDAå·¥å…·åŒ…æœªå®‰è£…")
    print()
    print("è§£å†³æ–¹æ¡ˆ:")
    print("  1. è¿è¡Œ: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
    print("  2. æˆ–å‚è€ƒ PYTORCH_GPU_INSTALL.md æ–‡æ¡£")

print()
